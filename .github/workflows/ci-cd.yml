name: Event-Driven Pipeline Deployment

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Create Lambda package
      run: |
        mkdir -p build
        cd lambda_fn
        zip -r ../lambda-function.zip .
        cd ..
        echo "Lambda package created"

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2

    - name: Terraform Init
      run: terraform init

    - name: Terraform Validate
      run: terraform validate

    - name: Terraform Plan
      run: terraform plan -input=false

    - name: Terraform Apply
      if: github.ref == 'refs/heads/main'
      run: terraform apply -auto-approve -input=false

    - name: Test Deployment
      if: github.ref == 'refs/heads/main'
      run: |
        # Upload a test JSON file
        cat > test-data.json << EOF
        [
          {"transaction_id": "1", "amount": 100, "user_id": "user1", "timestamp": "2024-01-01T10:00:00Z"},
          {"transaction_id": "2", "amount": 200, "user_id": "user2", "timestamp": "2024-01-01T11:00:00Z"}
        ]
        EOF
        
        # Upload to S3 to trigger processing
        aws s3 cp test-data.json s3://$(terraform output -raw raw_bucket_name)/test-data.json
        echo "Test file uploaded, Lambda should process it automatically"